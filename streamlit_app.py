"""
Streamlit Frontend for eMMC RAG Agent

A ChatGPT-like interface for querying eMMC protocol documentation.
"""

import streamlit as st
import httpx
import json
import asyncio
from typing import Dict, Any, List
import os
from pathlib import Path

# Page configuration
st.set_page_config(
    page_title="eMMC RAG Agent",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better UI
st.markdown("""
<style>
    .stChatMessage {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .user-message {
        background-color: #e3f2fd;
    }
    .assistant-message {
        background-color: #f5f5f5;
    }
    .code-block {
        background-color: #1e1e1e;
        color: #d4d4d4;
        padding: 1rem;
        border-radius: 0.5rem;
        overflow-x: auto;
    }
    .source-tag {
        display: inline-block;
        background-color: #e0e0e0;
        padding: 0.2rem 0.5rem;
        border-radius: 0.3rem;
        margin: 0.2rem;
        font-size: 0.85rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "api_url" not in st.session_state:
    st.session_state.api_url = "http://127.0.0.1:8000"

# Sidebar configuration
with st.sidebar:
    st.title("âš™ï¸ é…ç½®")
    
    # API Configuration
    st.subheader("API è®¾ç½®")
    api_url = st.text_input(
        "API åœ°å€",
        value=st.session_state.api_url,
        help="FastAPI åç«¯æœåŠ¡åœ°å€"
    )
    st.session_state.api_url = api_url
    
    # Retrieval Configuration
    st.subheader("æ£€ç´¢å‚æ•°")
    top_k = st.slider(
        "Top-K",
        min_value=1,
        max_value=20,
        value=8,
        help="æ£€ç´¢çš„æ–‡æ¡£æ•°é‡ï¼ˆæ¨è 8-10 ä»¥æé«˜å¬å›ç‡ï¼‰"
    )
    
    # Typing speed control
    st.subheader("æ˜¾ç¤ºæ•ˆæœ")
    typing_speed = st.slider(
        "æ‰“å­—é€Ÿåº¦",
        min_value=0,
        max_value=200,
        value=50,
        step=10,
        help="æ§åˆ¶æ–‡å­—æ˜¾ç¤ºé€Ÿåº¦ï¼ˆæ¯«ç§’ï¼‰ã€‚0 = æœ€å¿«ï¼Œ200 = æœ€æ…¢"
    )
    
    # Clear chat button
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    # System status
    st.divider()
    st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
    
    # Health check
    try:
        response = httpx.get(f"{api_url}/health", timeout=2.0)
        if response.status_code == 200:
            st.success("âœ… API æœåŠ¡æ­£å¸¸")
        else:
            st.error("âŒ API æœåŠ¡å¼‚å¸¸")
    except:
        st.error("âŒ æ— æ³•è¿æ¥åˆ° API")
    
    st.caption(f"ä¼šè¯æ¶ˆæ¯æ•°: {len(st.session_state.messages)}")

# Main chat interface
st.title("ğŸ” eMMC RAG Agent")
st.caption("åŸºäº RAG çš„ eMMC åè®®æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # Display sources if available
        if "sources" in message and message["sources"]:
            with st.expander("ğŸ“š å‚è€ƒæ¥æº"):
                for source in message["sources"]:
                    st.markdown(f"""
                    - **Page {source['page_num']}** ({source['content_type']})
                    {f"  - *{source['metadata'].get('caption', '')}*" if source['metadata'].get('caption') else ''}
                    """)
        
        # Display generated code if available
        if "code" in message and message["code"]:
            with st.expander("ğŸ’» ç”Ÿæˆçš„ä»£ç "):
                st.code(message["code"], language="python")

# Chat input
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # Add user message to chat
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Get assistant response
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # Response data
        response_data = {
            "full_response": "",
            "sources": [],
            "generated_code": None
        }
        
        try:
            # Call streaming API
            async def stream_response():
                async with httpx.AsyncClient(timeout=60.0) as client:
                    payload = {
                        "query": prompt,
                        "top_k": top_k,
                        "stream": True
                    }
                    
                    # Buffer for smoother typing effect
                    char_buffer = ""
                    buffer_size = 3  # æ¯æ¬¡æ˜¾ç¤º3ä¸ªå­—ç¬¦
                    
                    async with client.stream(
                        "POST",
                        f"{st.session_state.api_url}/chat_stream",
                        json=payload
                    ) as response:
                        async for line in response.aiter_lines():
                            if line.startswith("data: "):
                                data_str = line[6:]
                                
                                if data_str.strip() == "[DONE]":
                                    # Flush remaining buffer
                                    if char_buffer:
                                        response_data["full_response"] += char_buffer
                                        message_placeholder.markdown(response_data["full_response"])
                                    break
                                
                                try:
                                    event = json.loads(data_str)
                                    event_type = event.get("type")
                                    content = event.get("data")
                                    
                                    if event_type == "text_chunk":
                                        # Add to buffer
                                        char_buffer += content
                                        
                                        # Display when buffer reaches threshold
                                        if len(char_buffer) >= buffer_size:
                                            response_data["full_response"] += char_buffer
                                            message_placeholder.markdown(response_data["full_response"] + "â–Œ")
                                            char_buffer = ""
                                            # Small delay for typing effect (user-configurable)
                                            await asyncio.sleep(typing_speed / 1000.0)
                                    
                                    elif event_type == "text":
                                        # Fallback for non-streaming text
                                        response_data["full_response"] = content
                                        message_placeholder.markdown(response_data["full_response"] + "â–Œ")
                                    
                                    elif event_type == "tool_start":
                                        message_placeholder.info(
                                            f"ğŸ”§ æ­£åœ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: {content.get('test_name')}..."
                                        )
                                    
                                    elif event_type == "code_result":
                                        test_name, code = content
                                        response_data["generated_code"] = code
                                        response_data["full_response"] += f"\n\nâœ… å·²ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: `{test_name}`"
                                        message_placeholder.markdown(response_data["full_response"])
                                
                                except json.JSONDecodeError:
                                    pass
                
                # Final update without cursor
                message_placeholder.markdown(response_data["full_response"])
            
            # Run async function
            asyncio.run(stream_response())
            
            # Add assistant message to history
            assistant_message = {
                "role": "assistant",
                "content": response_data["full_response"]
            }
            
            if response_data["sources"]:
                assistant_message["sources"] = response_data["sources"]
            
            if response_data["generated_code"]:
                assistant_message["code"] = response_data["generated_code"]
            
            st.session_state.messages.append(assistant_message)
            
        except Exception as e:
            st.error(f"âŒ é”™è¯¯: {str(e)}")
            st.exception(e)

# Footer
st.divider()
st.caption("ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥è¯¢é—®å…³äº eMMC åè®®çš„ä»»ä½•é—®é¢˜ï¼Œä¾‹å¦‚ 'CMD6 å¦‚ä½•ä½¿ç”¨ï¼Ÿ' æˆ– 'ç”Ÿæˆ CMD24 çš„æµ‹è¯•ä»£ç '")
